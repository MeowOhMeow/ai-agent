{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1dC9nVxk3V_VPjUADsnFu8EiT-xnU1tGH","timestamp":1705327838785},{"file_id":"1jCegIzLIuqqcM85uVs3WCeAJiSoYq3oh","timestamp":1636374980563}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uLghRcAdqaph"},"source":["# Hybrid Demucs from Colab\n","\n","This supports the Demucs source separation model (https://github.com/facebookresearch/demucs/)\n","This is only for separation with pre-trained models, not training!\n","\n","You can either upload files manually (slow) or link your Google Drive account."]},{"cell_type":"code","metadata":{"id":"79JbZGcAqX3p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705411442357,"user_tz":-480,"elapsed":187550,"user":{"displayName":"chatgpt plus","userId":"02682092390507913364"}},"outputId":"bd64b792-10bc-47b9-cdc2-1eca87da1f89"},"source":["!python3 -m pip install -U git+https://github.com/facebookresearch/demucs#egg=demucs"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting demucs\n","  Cloning https://github.com/facebookresearch/demucs to /tmp/pip-install-ar044ar2/demucs_6c39c589f0f446689f935989be46d47c\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/demucs /tmp/pip-install-ar044ar2/demucs_6c39c589f0f446689f935989be46d47c\n","  Resolved https://github.com/facebookresearch/demucs to commit e976d93ecc3865e5757426930257e200846a520a\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting dora-search (from demucs)\n","  Downloading dora_search-0.1.12.tar.gz (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting einops (from demucs)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting julius>=0.2.3 (from demucs)\n","  Downloading julius-0.2.7.tar.gz (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting lameenc>=1.2 (from demucs)\n","  Downloading lameenc-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (239 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.8/239.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting openunmix (from demucs)\n","  Downloading openunmix-1.2.1-py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from demucs) (6.0.1)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from demucs) (2.1.0+cu121)\n","Collecting torchaudio<2.1,>=0.8 (from demucs)\n","  Downloading torchaudio-2.0.2-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from demucs) (4.66.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->demucs) (2.1.0)\n","Collecting torch>=1.8.1 (from demucs)\n","  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.8.1->demucs)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.8.1->demucs)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.8.1->demucs)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.8.1->demucs)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.8.1->demucs)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.8.1->demucs)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.8.1->demucs)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.8.1->demucs)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.8.1->demucs)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.8.1->demucs)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.8.1->demucs)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==2.0.0 (from torch>=1.8.1->demucs)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->demucs) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->demucs) (0.42.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->demucs) (3.27.9)\n","Collecting lit (from triton==2.0.0->torch>=1.8.1->demucs)\n","  Downloading lit-17.0.6.tar.gz (153 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting omegaconf (from dora-search->demucs)\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting retrying (from dora-search->demucs)\n","  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Collecting submitit (from dora-search->demucs)\n","  Downloading submitit-1.5.1-py3-none-any.whl (74 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting treetable (from dora-search->demucs)\n","  Downloading treetable-0.2.5.tar.gz (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openunmix->demucs) (1.23.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->demucs) (2.1.3)\n","Collecting antlr4-python3-runtime==4.9.* (from omegaconf->dora-search->demucs)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dora-search->demucs) (1.16.0)\n","Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from submitit->dora-search->demucs) (2.2.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->demucs) (1.3.0)\n","Building wheels for collected packages: demucs, julius, dora-search, antlr4-python3-runtime, treetable, lit\n","  Building wheel for demucs (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for demucs: filename=demucs-4.1.0a2-py3-none-any.whl size=83543 sha256=b338ce0b0b6726c54cc2b7c4f97e0177ceeb34728f0350f50c67e3cedcfaa968\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-kjyubb_u/wheels/45/e4/ca/7791f04b554e5433713e22900eaf11595e27c454fb65ac30ab\n","  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=495ac1ae8c5c2268ccda6f28b3c3e32b0ac56fed9864f87afa6f20263595085c\n","  Stored in directory: /root/.cache/pip/wheels/b9/b2/05/f883527ffcb7f2ead5438a2c23439aa0c881eaa9a4c80256f4\n","  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dora-search: filename=dora_search-0.1.12-py3-none-any.whl size=75092 sha256=259712bd5cb14d081d444cbf6e260b2142a7922e1ce58d9c4bbbc31e5e13f3eb\n","  Stored in directory: /root/.cache/pip/wheels/b1/c2/c0/bea5cc405497284d584b958f293ef32c23bad42ae5e44d973c\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=2f243701d6e2ad9a46b5d66ff5e4a6c4e1435ad781d57dc344b0a1d569f35e1f\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","  Building wheel for treetable (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for treetable: filename=treetable-0.2.5-py3-none-any.whl size=7333 sha256=8630cdf4a92bb3130e11bfb8b90a90cc1dd11bf45c615fc758283bcf68f6ed60\n","  Stored in directory: /root/.cache/pip/wheels/72/55/0e/91c3655bdb162446f8a7cd477579397544454a63ae7c599c0c\n","  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=8f84290ee8d11b111f05a53960c7c41bf428df2d6ad8ae3822fe1e4761027f85\n","  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n","Successfully built demucs julius dora-search antlr4-python3-runtime treetable lit\n","Installing collected packages: lit, lameenc, antlr4-python3-runtime, treetable, submitit, retrying, omegaconf, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, einops, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchaudio, openunmix, julius, dora-search, demucs\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.1.0\n","    Uninstalling triton-2.1.0:\n","      Successfully uninstalled triton-2.1.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.0+cu121\n","    Uninstalling torch-2.1.0+cu121:\n","      Successfully uninstalled torch-2.1.0+cu121\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.1.0+cu121\n","    Uninstalling torchaudio-2.1.0+cu121:\n","      Successfully uninstalled torchaudio-2.1.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n","torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n","torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 demucs-4.1.0a2 dora-search-0.1.12 einops-0.7.0 julius-0.2.7 lameenc-1.7.0 lit-17.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 omegaconf-2.3.0 openunmix-1.2.1 retrying-1.3.4 submitit-1.5.1 torch-2.0.1 torchaudio-2.0.2 treetable-0.2.5 triton-2.0.0\n"]}]},{"cell_type":"code","metadata":{"id":"a-2p6OoOrOZK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705412324550,"user_tz":-480,"elapsed":882196,"user":{"displayName":"chatgpt plus","userId":"02682092390507913364"}},"outputId":"4845ed3b-5b51-4f2d-8287-6f00e7ef4944"},"source":["# Please BE VERY CAREFUL, this will link your entire drive.\n","# So don't edit code, except the one that says 'Customize the following options',\n","# or you might mess up your files.\n","# IF YOU DO NO WANT TO LINK DRIVE, please see below for an alternative!\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"znCvBifRrO-b"},"source":["# Customize the following options!\n","model = \"htdemucs\"\n","extensions = [\"mp3\", \"wav\", \"ogg\", \"flac\"]  # we will look for all those file types.\n","# two_stems = None   # only separate one stems from the rest, for instance\n","two_stems = \"vocals\"\n","\n","# Options for the output audio.\n","mp3 = True\n","mp3_rate = 320\n","float32 = False  # output as float 32 wavs, unsused if 'mp3' is True.\n","int24 = False    # output as int24 wavs, unused if 'mp3' is True.\n","# You cannot set both `float32 = True` and `int24 = True` !!\n","\n","in_path = '/gdrive/MyDrive/demucs/'\n","out_path = '/gdrive/MyDrive/demucs_separated/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kMKN9BN4r37E"},"source":["#@title Useful functions, don't forget to execute\n","import io\n","from pathlib import Path\n","import select\n","from shutil import rmtree\n","import subprocess as sp\n","import sys\n","from typing import Dict, Tuple, Optional, IO\n","\n","from google.colab import files\n","\n","def find_files(in_path):\n","    out = []\n","    for file in Path(in_path).iterdir():\n","        if file.suffix.lower().lstrip(\".\") in extensions:\n","            out.append(file)\n","    return out\n","\n","def copy_process_streams(process: sp.Popen):\n","    def raw(stream: Optional[IO[bytes]]) -> IO[bytes]:\n","        assert stream is not None\n","        if isinstance(stream, io.BufferedIOBase):\n","            stream = stream.raw\n","        return stream\n","\n","    p_stdout, p_stderr = raw(process.stdout), raw(process.stderr)\n","    stream_by_fd: Dict[int, Tuple[IO[bytes], io.StringIO, IO[str]]] = {\n","        p_stdout.fileno(): (p_stdout, sys.stdout),\n","        p_stderr.fileno(): (p_stderr, sys.stderr),\n","    }\n","    fds = list(stream_by_fd.keys())\n","\n","    while fds:\n","        # `select` syscall will wait until one of the file descriptors has content.\n","        ready, _, _ = select.select(fds, [], [])\n","        for fd in ready:\n","            p_stream, std = stream_by_fd[fd]\n","            raw_buf = p_stream.read(2 ** 16)\n","            if not raw_buf:\n","                fds.remove(fd)\n","                continue\n","            buf = raw_buf.decode()\n","            std.write(buf)\n","            std.flush()\n","\n","def separate(inp=None, outp=None):\n","    inp = inp or in_path\n","    outp = outp or out_path\n","    cmd = [\"python3\", \"-m\", \"demucs.separate\", \"-o\", str(outp), \"-n\", model]\n","    if mp3:\n","        cmd += [\"--mp3\", f\"--mp3-bitrate={mp3_rate}\"]\n","    if float32:\n","        cmd += [\"--float32\"]\n","    if int24:\n","        cmd += [\"--int24\"]\n","    if two_stems is not None:\n","        cmd += [f\"--two-stems={two_stems}\"]\n","    files = [str(f) for f in find_files(inp)]\n","    if not files:\n","        print(f\"No valid audio files in {in_path}\")\n","        return\n","    print(\"Going to separate the files:\")\n","    print('\\n'.join(files))\n","    print(\"With command: \", \" \".join(cmd))\n","    p = sp.Popen(cmd + files, stdout=sp.PIPE, stderr=sp.PIPE)\n","    copy_process_streams(p)\n","    p.wait()\n","    if p.returncode != 0:\n","        print(\"Command failed, something went wrong.\")\n","\n","\n","def from_upload():\n","    out_path = Path('separated')\n","    in_path = Path('tmp_in')\n","\n","    if in_path.exists():\n","        rmtree(in_path)\n","    in_path.mkdir()\n","\n","    if out_path.exists():\n","        rmtree(out_path)\n","    out_path.mkdir()\n","\n","    uploaded = files.upload()\n","    for name, content in uploaded.items():\n","        (in_path / name).write_bytes(content)\n","    separate(in_path, out_path)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gr9OJvf-tYyt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705414802685,"user_tz":-480,"elapsed":2478139,"user":{"displayName":"chatgpt plus","userId":"02682092390507913364"}},"outputId":"8432228a-633c-47d4-9982-536cd319f5ad"},"source":["# This can be quite slow, in particular the loading, and saving from GDrive. Please be patient!\n","# This is from google drive! Also, this will separate all the files inside the MyDrive/demucs folder,\n","# so when you are happy with the results, remove the songs from there.\n","separate()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Going to separate the files:\n","/gdrive/MyDrive/demucs/EP1.mp3\n","/gdrive/MyDrive/demucs/EP2.mp3\n","/gdrive/MyDrive/demucs/EP3.mp3\n","/gdrive/MyDrive/demucs/EP4.mp3\n","/gdrive/MyDrive/demucs/EP5.mp3\n","/gdrive/MyDrive/demucs/EP6.mp3\n","/gdrive/MyDrive/demucs/EP7.mp3\n","/gdrive/MyDrive/demucs/EP8.mp3\n","/gdrive/MyDrive/demucs/EP9.mp3\n","/gdrive/MyDrive/demucs/EP10.mp3\n","/gdrive/MyDrive/demucs/EP11.mp3\n","/gdrive/MyDrive/demucs/EP12.mp3\n","With command:  python3 -m demucs.separate -o /gdrive/MyDrive/demucs_separated/ -n htdemucs --mp3 --mp3-bitrate=320 --two-stems=vocals\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://dl.fbaipublicfiles.com/demucs/hybrid_transformer/955717e8-8726e21a.th\" to /root/.cache/torch/hub/checkpoints/955717e8-8726e21a.th\n","100%|██████████| 80.2M/80.2M [00:01<00:00, 83.4MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Selected model is a bag of 1 models. You will see that many progress bars per track.\n","Separated tracks will be stored in /gdrive/MyDrive/demucs_separated/htdemucs\n","Separating track /gdrive/MyDrive/demucs/EP1.mp3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████████████| 1515.1499999999999/1515.1499999999999 [01:07<00:00, 22.55seconds/s]\n"]},{"output_type":"stream","name":"stdout","text":["Separating track /gdrive/MyDrive/demucs/EP2.mp3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████████████| 1456.6499999999999/1456.6499999999999 [00:58<00:00, 24.71seconds/s]\n"]},{"output_type":"stream","name":"stdout","text":["Separating track /gdrive/MyDrive/demucs/EP3.mp3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████████████| 1456.6499999999999/1456.6499999999999 [00:59<00:00, 24.36seconds/s]\n"]},{"output_type":"stream","name":"stdout","text":["Separating track /gdrive/MyDrive/demucs/EP4.mp3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████████████| 1456.6499999999999/1456.6499999999999 [01:00<00:00, 24.10seconds/s]\n"]},{"output_type":"stream","name":"stdout","text":["Separating track /gdrive/MyDrive/demucs/EP5.mp3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████████████| 1456.6499999999999/1456.6499999999999 [01:00<00:00, 24.15seconds/s]\n"]},{"output_type":"stream","name":"stdout","text":["Separating track /gdrive/MyDrive/demucs/EP6.mp3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████████████| 1456.6499999999999/1456.6499999999999 [01:00<00:00, 24.10seconds/s]\n"]},{"output_type":"stream","name":"stdout","text":["Separating track /gdrive/MyDrive/demucs/EP7.mp3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████████████| 1456.6499999999999/1456.6499999999999 [01:00<00:00, 24.14seconds/s]\n"]},{"output_type":"stream","name":"stdout","text":["Separating track /gdrive/MyDrive/demucs/EP8.mp3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████████████| 1456.6499999999999/1456.6499999999999 [01:00<00:00, 24.15seconds/s]\n"]},{"output_type":"stream","name":"stdout","text":["Separating track /gdrive/MyDrive/demucs/EP9.mp3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████████████| 1456.6499999999999/1456.6499999999999 [00:59<00:00, 24.28seconds/s]\n"]},{"output_type":"stream","name":"stdout","text":["Separating track /gdrive/MyDrive/demucs/EP10.mp3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████████████| 1456.6499999999999/1456.6499999999999 [01:00<00:00, 24.22seconds/s]\n"]},{"output_type":"stream","name":"stdout","text":["Separating track /gdrive/MyDrive/demucs/EP11.mp3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████████████| 1456.6499999999999/1456.6499999999999 [01:00<00:00, 24.22seconds/s]\n"]},{"output_type":"stream","name":"stdout","text":["Separating track /gdrive/MyDrive/demucs/EP12.mp3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████████████| 1456.6499999999999/1456.6499999999999 [01:00<00:00, 24.24seconds/s]\n"]}]},{"cell_type":"code","metadata":{"id":"v__3gMJawTD0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"426c5f61-87df-4b1d-dd95-50192bf9629e"},"source":["# This is manual upload and download :)\n","from_upload()\n","!zip -r separated.zip separated\n","files.download('./separated.zip')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-2b059699-0674-43d1-a6d2-b024b036ee4d\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-2b059699-0674-43d1-a6d2-b024b036ee4d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}}]}]}